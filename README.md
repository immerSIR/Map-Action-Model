<p align="center">
  <img src="https://dashboard.map-action.com/static/media/logo.ff03b7a9.png" width="100" />
</p>
<p align="center">
    <h1 align="center">MAP-ACTION-MODEL</h1>
</p>
<p align="center">
    <em></em>
</p>
<p align="center">
	<img src="https://img.shields.io/github/license/223MapAction/Map-Action-Model?style=flat&color=0080ff" alt="license">
	<img src="https://img.shields.io/github/last-commit/223MapAction/Map-Action-Model?style=flat&color=0080ff" alt="last-commit">
	<img src="https://img.shields.io/github/languages/top/223MapAction/Map-Action-Model?style=flat&color=0080ff" alt="repo-top-language">
	<img src="https://img.shields.io/github/languages/count/223MapAction/Map-Action-Model?style=flat&color=0080ff" alt="repo-language-count">
<p>
<p align="center">
		<em>Developed with the software and tools below.</em>
</p>
<p align="center">
	<img src="https://img.shields.io/badge/Jupyter-F37626.svg?style=flat&logo=Jupyter&logoColor=white" alt="Jupyter">
	<img src="https://img.shields.io/badge/YAML-CB171E.svg?style=flat&logo=YAML&logoColor=white" alt="YAML">
	<img src="https://img.shields.io/badge/PowerShell-5391FE.svg?style=flat&logo=PowerShell&logoColor=white" alt="PowerShell">
	<img src="https://img.shields.io/badge/Python-3776AB.svg?style=flat&logo=Python&logoColor=white" alt="Python">
	<img src="https://img.shields.io/badge/Docker-2496ED.svg?style=flat&logo=Docker&logoColor=white" alt="Docker">
	<img src="https://img.shields.io/badge/GitHub%20Actions-2088FF.svg?style=flat&logo=GitHub-Actions&logoColor=white" alt="GitHub%20Actions">
	<img src="https://img.shields.io/badge/DVC-13ADC7.svg?style=flat&logo=DVC&logoColor=white" alt="DVC">
</p>
<hr>

## üîó Quick Links

> - [üìç Overview](#-overview)
> - [üì¶ Features](#-features)
> - [üìÇ Repository Structure](#-repository-structure)
> - [üß© Modules](#-modules)
> - [üöÄ Getting Started](#-getting-started)
>   - [‚öôÔ∏è Installation](#Ô∏è-installation)
>   - [ü§ñ Running Map-Action-Model](#-running-Map-Action-Model)
>   - [üß™ Tests](#-tests)
> - [üõ† Project Roadmap](#-project-roadmap)
> - [ü§ù Contributing](#-contributing)
> - [üìÑ License](#-license)
> - [Code of conduct](#-code-of-conduct)
> - [üëè Acknowledgments](#-acknowledgments)

---

## üìç Overview



---

## üì¶ Features

|    |   Feature         | Description |
|----|-------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| ‚öôÔ∏è  | **Architecture**  | The project's architecture is not described in the provided information. More details about the architecture would be needed to provide a complete analysis. |
| üî© | **Code Quality**  | The code quality and style are not mentioned in the provided information. More details about code quality practices and standards followed would be needed for a complete analysis. |
| üìÑ | **Documentation** | The extent and quality of documentation are not specified. More information about the documentation, such as the presence of documentation files or the clarity and coverage of the existing documentation, would be needed for a complete analysis. |
| üîå | **Integrations**  | The key integrations and external dependencies are not mentioned in the provided information. More details about the integrations and dependencies used in the project would be needed for a complete analysis. |
| üß© | **Modularity**    | The modularity and reusability of the codebase are not specified. More information about the organization and separation of code into modules or components would be needed for a complete analysis. |
| üß™ | **Testing**       | The testing frameworks and tools used are not mentioned in the provided information. More details about the testing practices and tools employed in the project would be needed for a complete analysis. |
| ‚ö°Ô∏è  | **Performance**   | The efficiency, speed, and resource usage of the project are not described in the provided information. More details about the performance optimization techniques or benchmarks conducted would be needed for a complete analysis. |
| üõ°Ô∏è | **Security**      | The measures used for data protection and access control are not specified. More information about the security practices, such as encryption, authentication, or authorization mechanisms, would be needed for a complete analysis. |
| üì¶ | **Dependencies**  | The key external libraries and dependencies are not listed in the provided information. A list of the specific libraries and dependencies used in the project would be needed for a complete analysis. |
| üöÄ | **Scalability**   | The ability to handle increased traffic and load is not mentioned in the provided information. More details about the project's scalability features, such as horizontal scaling or load balancing capabilities, would be needed for a complete analysis. |


---

## üìÇ Repository Structure

```sh
‚îî‚îÄ‚îÄ Map-Action-Model/
    ‚îú‚îÄ‚îÄ .github
    ‚îÇ   ‚îî‚îÄ‚îÄ workflows
    ‚îÇ       ‚îî‚îÄ‚îÄ training-on-gpu.yml
    ‚îú‚îÄ‚îÄ Dockerfile
    ‚îú‚îÄ‚îÄ LICENCE
    ‚îú‚îÄ‚îÄ code
    ‚îÇ   ‚îú‚îÄ‚îÄ map_action_classification_model
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ .zen
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ TFLearning.ipynb
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dagshub_data_load.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_loading_pipeline.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_transform.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ m_a_model.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ m_a_utility.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pipelines
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ step
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ training_utils.py
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utilities.ipynb
    ‚îÇ   ‚îú‚îÄ‚îÄ map_action_yolo_detection
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data.yaml
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ runs
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ yolo_train.ipynb
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ yolo_train.py
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ yolov8n.pt
    ‚îÇ   ‚îú‚îÄ‚îÄ mapaction_image_captioning_model
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ decoder_rnn.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ encoder_cnn.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ training.py
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ vocabulary.py
    ‚îÇ   ‚îú‚îÄ‚îÄ mapaction_object_detection_model
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ get_mlflow_ex_id.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ m_a_detection_model.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ map_action_data_loader.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ map_action_tranform.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ testing.ipynb
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ training_utils.py
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utility.py
    ‚îÇ   ‚îú‚îÄ‚îÄ mapaction_segementation_model
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ check_dataloader.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_transform.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model_tester.ipynb
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ training_pipeline.py
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utility.py
    ‚îÇ   ‚îú‚îÄ‚îÄ train.py
    ‚îÇ   ‚îî‚îÄ‚îÄ vision_dir
    ‚îÇ       ‚îú‚îÄ‚îÄ coco_eval.py
    ‚îÇ       ‚îú‚îÄ‚îÄ coco_utils.py
    ‚îÇ       ‚îú‚îÄ‚îÄ engine.py
    ‚îÇ       ‚îú‚îÄ‚îÄ group_by_aspect_ratio.py
    ‚îÇ       ‚îú‚îÄ‚îÄ presets.py
    ‚îÇ       ‚îú‚îÄ‚îÄ train.py
    ‚îÇ       ‚îú‚îÄ‚îÄ transforms.py
    ‚îÇ       ‚îî‚îÄ‚îÄ utils.py
    ‚îú‚îÄ‚îÄ data.dvc
    ‚îú‚îÄ‚îÄ ma_env
    ‚îÇ   ‚îú‚îÄ‚îÄ bin
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Activate.ps1
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ activate
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ activate.csh
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ activate.fish
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pip
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pip3
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pip3.10
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ python
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ python3
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ python3.10
    ‚îÇ   ‚îú‚îÄ‚îÄ lib
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ python3.10
    ‚îÇ   ‚îî‚îÄ‚îÄ lib64
    ‚îÇ       ‚îî‚îÄ‚îÄ python3.10
    ‚îú‚îÄ‚îÄ model
    ‚îÇ   ‚îî‚îÄ‚îÄ main.py
    ‚îî‚îÄ‚îÄ requirements.txt
```

---

## üß© Modules

<details closed><summary>.</summary>

| File                                                                                              | Summary                                                                                                                                                                                                                                                                                                                                                                                 |
| ---                                                                                               | ---                                                                                                                                                                                                                                                                                                                                                                                     |
| [LICENCE](https://github.com/223MapAction/Map-Action-Model/blob/master/LICENCE)                   | This code snippet is part of the Map-Action-Model repository. It includes various machine learning models and utilities for map action classification, YOLO object detection, and image captioning. The code focuses on data loading, data transformation, model training, and utility functions.                                                                                       |
| [requirements.txt](https://github.com/223MapAction/Map-Action-Model/blob/master/requirements.txt) | The code snippet is located in the `code/map_action_classification_model` directory within the parent repository. It consists of several files and modules for training a map action classification model. The main purpose of this code is to provide functionality for data loading, data transformation, model training, and utility functions related to map action classification. |
| [Dockerfile](https://github.com/223MapAction/Map-Action-Model/blob/master/Dockerfile)             | The Dockerfile in the codebase sets up the PyTorch environment with necessary dependencies and installs additional packages. It also configures GPU support for PyTorch, making it ready for running GPU-accelerated code. This Dockerfile is critical for ensuring a consistent and reliable development environment for the codebase.                                                 |
| [.gitignore](https://github.com/223MapAction/Map-Action-Model/blob/master/.gitignore)             | Code snippet:.gitignoreThis code snippet is a configuration file that specifies patterns of files and directories to be ignored by Git when tracking changes. It excludes files such as compiled code, build artifacts, logs, and temporary files from being committed to the repository.                                                                                               |
| [data.dvc](https://github.com/223MapAction/Map-Action-Model/blob/master/data.dvc)                 | The code snippet in the `code/map_action_classification_model` directory is responsible for training a machine learning model for map action classification. It includes data loading, data transformation, and model training functionalities. The code achieves the goal of creating a model that can classify map actions accurately based on input data.                            |

</details>

<details closed><summary>model</summary>

| File                                                                                  | Summary                                                                                                                                                                                                                                                                           |
| ---                                                                                   | ---                                                                                                                                                                                                                                                                               |
| [main.py](https://github.com/223MapAction/Map-Action-Model/blob/master/model/main.py) | This code snippet, located in the `model/main.py` file, plays a critical role in the parent repository's architecture. It performs important functions related to the main model of the system, but without further details, the specific features achieved cannot be determined. |

</details>


<details closed><summary>code</summary>

| File                                                                                   | Summary                                                                                                                                                                                                                                                                      |
| ---                                                                                    | ---                                                                                                                                                                                                                                                                          |
| [train.py](https://github.com/223MapAction/Map-Action-Model/blob/master/code/train.py) | The `train.py` code snippet is responsible for training a map action instance segmentation model. It imports the necessary dependencies, initializes the model, sets the device (GPU or CPU), defines the optimizer, and sets the learning rate, momentum, and weight decay. |

</details>

<details closed><summary>code.mapaction_segementation_model</summary>

| File                                                                                                                                         | Summary                                                                                                                                                                                                                                                                                                                                                                                                                  |
| ---                                                                                                                                          | ---                                                                                                                                                                                                                                                                                                                                                                                                                      |
| [train.py](https://github.com/223MapAction/Map-Action-Model/blob/master/code/mapaction_segementation_model/train.py)                         | The code in `train.py` trains an instance segmentation model using the MapAction dataset. It initializes the model, defines the loss function and optimizer, and trains the model for a specified number of epochs. The trained model is then saved to a specified path.                                                                                                                                                 |
| [check_dataloader.py](https://github.com/223MapAction/Map-Action-Model/blob/master/code/mapaction_segementation_model/check_dataloader.py)   | The code snippet in `check_dataloader.py` is responsible for loading data and checking the DataLoader in the Map Action Segmentation Model. It ensures that the data is loaded onto the CPU or GPU depending on availability and prints the loaded targets.                                                                                                                                                              |
| [data_loader.py](https://github.com/223MapAction/Map-Action-Model/blob/master/code/mapaction_segementation_model/data_loader.py)             | The code snippet in `data_loader.py` is responsible for setting up data loaders for training and testing a segmentation model. It imports necessary libraries, defines a custom dataset, applies data transformations, and creates data loaders with batch processing and shuffling capabilities.                                                                                                                        |
| [utility.py](https://github.com/223MapAction/Map-Action-Model/blob/master/code/mapaction_segementation_model/utility.py)                     | This code snippet defines a `MapActionDataset` class that represents a dataset for image segmentation. It loads images and corresponding masks, performs various data preprocessing steps, and returns the processed data as input and target pairs.                                                                                                                                                                     |
| [training_pipeline.py](https://github.com/223MapAction/Map-Action-Model/blob/master/code/mapaction_segementation_model/training_pipeline.py) | This code snippet represents the training pipeline for a segmentation model in the Map-Action-Model repository. It defines a `ModelTrainer` class that trains the model using a train loader, optimizer, and loss function. It also includes methods to perform the training and testing steps, returning the results.                                                                                                   |
| [data_transform.py](https://github.com/223MapAction/Map-Action-Model/blob/master/code/mapaction_segementation_model/data_transform.py)       | This code snippet, located at `code/mapaction_segementation_model/data_transform.py`, defines a function `get_transform` that returns a composition of image transformations using the torchvision library. These transformations include random horizontal flipping, converting images to float tensors, and converting tensors to pure tensors.                                                                        |
| [model.py](https://github.com/223MapAction/Map-Action-Model/blob/master/code/mapaction_segementation_model/model.py)                         | This code snippet defines a function that creates an instance segmentation model for MapAction. It loads a pretrained model, replaces the head and mask predictor, and returns the modified model.                                                                                                                                                                                                                       |
| [model_tester.ipynb](https://github.com/223MapAction/Map-Action-Model/blob/master/code/mapaction_segementation_model/model_tester.ipynb)     | The code snippet is a critical component in the parent repository's architecture. It serves as a Tech Lead's and Software Engineer's tool to deliver efficient and effective software solutions. The code achieves this by implementing advanced technology, following best practices, and ensuring scalability and reliability. The codebase also includes documentation, unit tests, and continuous integration tools. |

</details>

<details closed><summary>code.mapaction_image_captioning_model</summary>

| File                                                                                                                                | Summary                                                                                                                                                                                                                                                                                                                                                                       |
| ---                                                                                                                                 | ---                                                                                                                                                                                                                                                                                                                                                                           |
| [vocabulary.py](https://github.com/223MapAction/Map-Action-Model/blob/master/code/mapaction_image_captioning_model/vocabulary.py)   | The `Vocabulary` class in the `vocabulary.py` file is responsible for creating and managing a vocabulary for image captioning. It initializes the vocabulary, adds special words, and builds the vocabulary by tokenizing captions. The vocabulary can be loaded from a file or created from scratch.                                                                         |
| [train.py](https://github.com/223MapAction/Map-Action-Model/blob/master/code/mapaction_image_captioning_model/train.py)             | The `train.py` code in the `mapaction_image_captioning_model` module is responsible for training an image captioning model. It loads data, initializes the encoder and decoder models, defines the loss function and optimizer, and performs training iterations. The code also sets the GPU device if available and calculates the total number of training steps per epoch. |
| [encoder_cnn.py](https://github.com/223MapAction/Map-Action-Model/blob/master/code/mapaction_image_captioning_model/encoder_cnn.py) | The `EncoderCNN` class in `encoder_cnn.py` is a critical component of the Map-Action-Model repository. It takes in images, extracts features using a pre-trained ResNet model, and applies linear and batch normalization layers to generate embedded features for image captioning.                                                                                          |
| [data_loader.py](https://github.com/223MapAction/Map-Action-Model/blob/master/code/mapaction_image_captioning_model/data_loader.py) | This code snippet contains a data loader function and a dataset class for the image captioning model. It provides the necessary functions to load and preprocess image data and captions for training and testing the model.                                                                                                                                                  |
| [decoder_rnn.py](https://github.com/223MapAction/Map-Action-Model/blob/master/code/mapaction_image_captioning_model/decoder_rnn.py) | The `DecoderRNN` class in the `decoder_rnn.py` file is responsible for implementing the decoder component of an image captioning model. It takes in image features and caption inputs, processes them through an LSTM network, and generates output predictions using linear layers.                                                                                          |
| [training.py](https://github.com/223MapAction/Map-Action-Model/blob/master/code/mapaction_image_captioning_model/training.py)       | This code snippet, located at `code/mapaction_image_captioning_model/training.py`, implements the training loop for an image captioning model. It iterates over epochs and steps, computes and updates the model's parameters using backpropagation, and logs the training statistics. Additionally, it saves the model weights at specified intervals.                       |

</details>

<details closed><summary>code.mapaction_object_detection_model</summary>

| File                                                                                                                                                      | Summary                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |
| ---                                                                                                                                                       | ---                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |
| [train.py](https://github.com/223MapAction/Map-Action-Model/blob/master/code/mapaction_object_detection_model/train.py)                                   | The `train.py` code in the `mapaction_object_detection_model` directory trains an instance segmentation model using the Map Action dataset. It utilizes MLflow for experiment tracking and saves the trained model to a specified location. The code also sets up the necessary data loaders, loss function, optimizer, and training parameters.                                                                                                                                                |
| [training_utils.py](https://github.com/223MapAction/Map-Action-Model/blob/master/code/mapaction_object_detection_model/training_utils.py)                 | This code snippet is part of the Map Action Model repository and is located in the `code/mapaction_object_detection_model/training_utils.py` file. It contains the `ModelTrainer` class responsible for training and evaluating an object detection model. The class includes methods for training and testing the model, as well as extracting predictions and calculating precision, recall, and F1 scores. The code also integrates with MLflow for logging training parameters and metrics. |
| [map_action_data_loader.py](https://github.com/223MapAction/Map-Action-Model/blob/master/code/mapaction_object_detection_model/map_action_data_loader.py) | This code snippet implements the data loading functionality for the map action object detection model. It loads and preprocesses the dataset, creates data loaders for training and testing with specified batch sizes, and handles collation of batches.                                                                                                                                                                                                                                       |
| [get_mlflow_ex_id.py](https://github.com/223MapAction/Map-Action-Model/blob/master/code/mapaction_object_detection_model/get_mlflow_ex_id.py)             | The code snippet in `get_mlflow_ex_id.py` retrieves the experiment ID for the mapaction_object_detection_model from the MLflow tracking server. If the experiment does not exist, it creates a new experiment and returns the ID.                                                                                                                                                                                                                                                               |
| [utility.py](https://github.com/223MapAction/Map-Action-Model/blob/master/code/mapaction_object_detection_model/utility.py)                               | The `utility.py` file in the `mapaction_object_detection_model` module of the repository is responsible for defining the `MapActionDataset` class. This class is a custom dataset that loads and processes images and annotations for object detection tasks. It handles tasks such as loading the image, extracting bounding box coordinates, and converting the data into tensors for use in the object detection model.                                                                      |
| [testing.ipynb](https://github.com/223MapAction/Map-Action-Model/blob/master/code/mapaction_object_detection_model/testing.ipynb)                         | This code snippet is a critical component of the parent repository's architecture. It serves as a Tech Lead and Software Engineer, delivering brilliant solutions and features.                                                                                                                                                                                                                                                                                                                 |
| [m_a_detection_model.py](https://github.com/223MapAction/Map-Action-Model/blob/master/code/mapaction_object_detection_model/m_a_detection_model.py)       | This code snippet defines a function that creates an instance segmentation model for object detection. It utilizes a pre-trained Faster R-CNN model from torchvision and replaces the head with a new one for the desired number of classes.                                                                                                                                                                                                                                                    |
| [map_action_tranform.py](https://github.com/223MapAction/Map-Action-Model/blob/master/code/mapaction_object_detection_model/map_action_tranform.py)       | The code snippet in the file map_action_transform.py provides a function, `get_transform(train)`, that returns a sequence of image transformations. These transformations include converting an image from PIL format to PyTorch Tensor and applying data augmentation techniques like random horizontal and vertical flips, color jitter, and more. The function is used in the object detection model training pipeline to preprocess the input images.                                       |

</details>

<details closed><summary>code.map_action_yolo_detection</summary>

| File                                                                                                                             | Summary                                                                                                                                                                                                                                                                                                    |
| ---                                                                                                                              | ---                                                                                                                                                                                                                                                                                                        |
| [data.yaml](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/data.yaml)               | The code snippet in the `map_action_yolo_detection/data.yaml` file contains the file paths for training, validation, and testing images, as well as the number of classes and their names for a YOLO object detection model in the Map-Action-Model repository.                                            |
| [yolo_train.ipynb](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/yolo_train.ipynb) | This code snippet, located in the `code/map_action_yolo_detection/yolo_train.ipynb` file, is responsible for training a YOLO object detection model. It focuses on training the model using YOLOv8 and provides the necessary code and configuration files for the training process.                       |
| [yolo_train.py](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/yolo_train.py)       | This code snippet in the code/map_action_yolo_detection/yolo_train.py file is responsible for training a YOLO model for object detection. It loads a pretrained model, trains it on a specified dataset, evaluates its performance, and makes predictions on images. The results are visualized and saved. |

</details>

<details closed><summary>code.map_action_yolo_detection.runs.detect.train</summary>

| File                                                                                                                                 | Summary                                                                                                                                                                                                                                                                                                     |
| ---                                                                                                                                  | ---                                                                                                                                                                                                                                                                                                         |
| [args.yaml](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/detect/train/args.yaml) | This code snippet is responsible for training the YOLOv8n model for object detection. It uses the configuration parameters provided in the `args.yaml` file to specify training settings such as epochs, batch size, image size, and more. The trained model is saved in the `runs/detect/train` directory. |

</details>

<details closed><summary>code.map_action_yolo_detection.runs.mlflow.452260836794962566</summary>

| File                                                                                                                                              | Summary                                                                                                                                                                                                                                                                                                                        |
| ---                                                                                                                                               | ---                                                                                                                                                                                                                                                                                                                            |
| [meta.yaml](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/meta.yaml) | The code in the `map_action_yolo_detection` module of the repository is responsible for implementing object detection using the YOLOv8 model. It includes data loading, training, and inference functionalities. The code snippet specifically deals with managing the metadata of the MLflow experiment for the YOLOv8 model. |

</details>

<details closed><summary>code.map_action_yolo_detection.runs.mlflow.452260836794962566.3bf8731e14554e2c99db9c7292999de0</summary>

| File                                                                                                                                                                               | Summary                                                                                                                                                                                                                                                                                                                                                                                      |
| ---                                                                                                                                                                                | ---                                                                                                                                                                                                                                                                                                                                                                                          |
| [meta.yaml](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/meta.yaml) | This code snippet is part of the Map-Action-Model repository and is located in the code/map_action_yolo_detection folder. It appears to be related to training a YOLO-based object detection model. The specific file runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/meta.yaml contains metadata for an MLflow run with a unique ID and information about the artifact URI. |

</details>

<details closed><summary>code.map_action_yolo_detection.runs.mlflow.452260836794962566.3bf8731e14554e2c99db9c7292999de0.params</summary>

| File                                                                                                                                                                                                  | Summary                                                                                                                                                                                                                                                                                                                                                                                                                  |
| ---                                                                                                                                                                                                   | ---                                                                                                                                                                                                                                                                                                                                                                                                                      |
| [tracker](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/tracker)                 | The code snippet in `code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/tracker/botsort.yaml` contains critical parameters for the object detection model in the Map-Action-Model repository. These parameters are essential for tracking and sorting objects detected in images or videos.                                                                           |
| [model](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/model)                     | The code snippet `yolov8n.pt` in the `map_action_yolo_detection` directory of the repository is a pre-trained YOLOv8 model used for object detection.                                                                                                                                                                                                                                                                    |
| [plots](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/plots)                     | The code snippet is part of the Map Action Model repository and is located in the `code/map_action_yolo_detection` directory. It is focused on YOLO object detection and includes files such as `data.yaml`, `yolo_train.ipynb`, `yolo_train.py`, and `yolov8n.pt`. It contributes to the repository's architecture by providing implementation for YOLO-based object detection.                                         |
| [cos_lr](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/cos_lr)                   | The code in the `code/map_action_yolo_detection` directory is responsible for running a YOLO object detection model. It includes files like `yolo_train.py` and `yolov8n.pt` to train and use the model. The file `data.yaml` in the same directory contains the configuration for the data used in the training process.                                                                                                |
| [copy_paste](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/copy_paste)           | This code snippet is part of the Map-Action-Model repository and is located in the code/map_action_yolo_detection directory. It is related to the YOLO object detection model.                                                                                                                                                                                                                                           |
| [visualize](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/visualize)             | This code snippet is part of the Map Action Model repository. It focuses on the YOLO-based object detection model. The code performs visualizing parameters for a specific MLflow run.                                                                                                                                                                                                                                   |
| [split](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/split)                     | The code snippet in the map_action_yolo_detection module is responsible for training and running the YOLO object detection model. The relevant file path contains the split parameter used for validation.                                                                                                                                                                                                               |
| [close_mosaic](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/close_mosaic)       | This code snippet is part of the Map-Action-Model repository and is located in the code/map_action_yolo_detection directory. It is related to the YOLO object detection model. The specific file mentioned is runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/close_mosaic and its contents are 10.                                                                                               |
| [patience](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/patience)               | The code snippet in the `map_action_yolo_detection` folder is responsible for training a YOLO object detection model. It utilizes the MLflow framework and has a patience parameter set to 50.                                                                                                                                                                                                                           |
| [profile](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/profile)                 | The code snippet is part of the Map-Action-Model repository and is located at `code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/profile`. It contains a parameter file with the value `False`. The purpose and functionality of this code snippet cannot be determined without further context.                                                                     |
| [augment](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/augment)                 | The `map_action_yolo_detection` module in the codebase is responsible for training a YOLO object detection model. It contains files for data loading, training, and model evaluation. It uses the MLflow framework for experiment tracking. The specific code snippet being referenced is related to the data augmentation parameter in the YOLO training configuration.                                                 |
| [single_cls](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/single_cls)           | This code snippet in the map_action_yolo_detection directory is responsible for training a YOLO object detection model. The code reads parameters from a file and sets the single_cls parameter to False.                                                                                                                                                                                                                |
| [box](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/box)                         | The code snippet located in the `code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/box` file is responsible for storing the value `7.5` as a parameter in the MLflow experiment.                                                                                                                                                                                     |
| [hsv_h](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/hsv_h)                     | The code in the map_action_yolo_detection module is responsible for training and using a YOLO object detection model. The hsv_h parameter, stored in the given file, represents the hue value used for color filtering in the model. This code helps in detecting objects in images.                                                                                                                                     |
| [opset](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/opset)                     | This code snippet is located in the `code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/opset` file. However, its contents are not provided.                                                                                                                                                                                                                          |
| [degrees](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/degrees)                 | This code snippet is part of the Map-Action-Model repository. It is located in the `code/map_action_yolo_detection` directory and contains files related to YOLO object detection. This specific file (`degrees`) contains the value 0.0 as a parameter for the YOLO model.                                                                                                                                              |
| [show_conf](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/show_conf)             | This code snippet, located in the `map_action_yolo_detection` folder, is responsible for showing the configuration when the `show_conf` parameter is set to True. It is part of the parent repository's architecture for object detection with YOLO.                                                                                                                                                                     |
| [show_labels](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/show_labels)         | The code snippet in the `map_action_yolo_detection` directory is responsible for training a YOLO object detection model. It uses MLflow to track and log the training process. The code also includes a parameter (`show_labels`) that determines whether or not to show the labels during the training.                                                                                                                 |
| [epochs](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/epochs)                   | This code snippet is part of the Map-Action-Model repository's architecture. It contributes to the map_action_yolo_detection component by specifying the number of epochs for training, with a value of 20.                                                                                                                                                                                                              |
| [max_det](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/max_det)                 | The code snippet is part of the Map Action Model repository. Its main role is to handle object detection using the YOLO algorithm. The specific code snippet is related to the maximum number of detections allowed, which is specified as 300.                                                                                                                                                                          |
| [hsv_s](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/hsv_s)                     | The code snippet `code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/hsv_s` contains the parameter value `0.7` for the HSV saturation threshold used in the YOLO detection model.                                                                                                                                                                                     |
| [save_conf](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/save_conf)             | The code snippet in the `runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/save_conf` file is responsible for determining whether to save the configuration or not. It achieves this by storing a boolean value (`False`) in the file.                                                                                                                                                              |
| [nms](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/nms)                         | The code snippet in code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/nms contributes to the repository's architecture by providing configuration parameters related to non-maximum suppression (NMS) in the YOLO (You Only Look Once) object detection model.                                                                                                       |
| [seed](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/seed)                       | This code snippet, located in the `map_action_yolo_detection` folder, runs a YOLO object detection model for map action classification. It uses MLflow for tracking and has a seed value of 0.                                                                                                                                                                                                                           |
| [show_boxes](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/show_boxes)           | The code snippet in the map_action_yolo_detection directory performs object detection using the YOLOv8 model. It detects objects in images and shows bounding boxes around them. The specific file show_boxes in the MLflow run folder sets the parameter to display the boxes.                                                                                                                                          |
| [pretrained](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/pretrained)           | This code snippet in the map_action_yolo_detection module is responsible for training a YOLO object detection model. It utilizes pretrained weights during the training process.                                                                                                                                                                                                                                         |
| [momentum](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/momentum)               | The code snippet in the map_action_yolo_detection folder is responsible for training a YOLO object detection model. It utilizes MLflow for tracking and optimization, with the momentum parameter set to 0.937.                                                                                                                                                                                                          |
| [scale](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/scale)                     | The code snippet in `code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/scale` sets the scale parameter for YOLO object detection in the Map Action Model repository.                                                                                                                                                                                                 |
| [save_frames](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/save_frames)         | The code snippet in the `code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/save_frames` file controls the saving of frames during object detection using the YOLO algorithm.                                                                                                                                                                                         |
| [perspective](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/perspective)         | This code snippet is part of the Map-Action-Model repository and is responsible for running the YOLO object detection model. It uses the provided parameters for perspective.                                                                                                                                                                                                                                            |
| [optimize](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/optimize)               | This code snippet in the `map_action_yolo_detection` directory is responsible for optimizing the YOLO detection model. It sets the optimization parameter to `False`.                                                                                                                                                                                                                                                    |
| [overlap_mask](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/overlap_mask)       | The code snippet in the `map_action_yolo_detection` module is responsible for running and evaluating a YOLO object detection model. It generates bounding box predictions and masks for detected objects. The specific file `overlap_mask` contains a boolean value indicating whether the predicted mask should overlap the bounding box.                                                                               |
| [fliplr](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/fliplr)                   | The code snippet in the `map_action_yolo_detection` module of the repository is responsible for performing object detection using the YOLO algorithm. The specific code file mentioned (`runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/fliplr`) contains a parameter value of 0.5, which is likely used to control the horizontal flipping of images during training or testing.                |
| [source](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/source)                   | This code snippet, located in the `code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/source` file, appears to contain parameters or configuration settings for the YOLO object detection model used in the Map Action project. It is important for defining and tuning the behavior of the model during training and inference.                                      |
| [translate](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/translate)             | The code snippet in the map_action_yolo_detection directory of the repository is responsible for running the YOLO object detection model. It utilizes MLflow to store and retrieve model parameters.                                                                                                                                                                                                                     |
| [warmup_epochs](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/warmup_epochs)     | This code snippet is part of the Map-Action-Model repository and is related to the map_action_yolo_detection component. It contains code for training a YOLO object detection model and specifies the number of warmup epochs to use during training.                                                                                                                                                                    |
| [fraction](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/fraction)               | The code snippet in `code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/fraction` retrieves the fraction parameter value, which is set to 1.0.                                                                                                                                                                                                                        |
| [amp](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/amp)                         | The code snippet in the `code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/amp` file enables automatic mixed precision training for the YOLO object detection model in the Map Action project.                                                                                                                                                                       |
| [lrf](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/lrf)                         | This code snippet is part of the Map Action YOLO Detection model in the Map-Action-Model repository. It contributes to the model training process by setting a learning rate parameter to 0.01.                                                                                                                                                                                                                          |
| [val](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/val)                         | The code snippet in `code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/val` is responsible for validating the performance of the YOLO object detection model in the Map Action Model repository. It confirms that the validation was successful by outputting `True`.                                                                                                |
| [save_json](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/save_json)             | The code snippet in the map_action_yolo_detection directory is responsible for training and running a YOLO object detection model. It includes data loading, model training, and model evaluation. The code does not save the model as a JSON file.                                                                                                                                                                      |
| [retina_masks](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/retina_masks)       | This code snippet is part of the Map-Action-Model repository. It focuses on the YOLO object detection model and its training process. The code achieves the training of the YOLO model using specified parameters, enhancing object detection capabilities.                                                                                                                                                              |
| [cfg](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/cfg)                         | The code in the `map_action_yolo_detection` directory is responsible for training a YOLO object detection model. It uses a configuration file located at `code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/cfg` to specify the model's architecture and training parameters.                                                                                        |
| [kobj](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/kobj)                       | The code snippet is part of the Map-Action-Model repository's architecture. It focuses on the implementation of the YOLO object detection model and includes the necessary files and configurations. The specific file mentioned stores a parameter value.                                                                                                                                                               |
| [simplify](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/simplify)               | This code snippet is part of the `Map-Action-Model` repository. It focuses on the YOLO object detection model and includes files for training and running the model. The specific file mentioned is about a parameter called simplify, which is set to False.                                                                                                                                                            |
| [keras](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/keras)                     | Summary: The code snippet is part of the Map-Action-Model repository and is located in the map_action_yolo_detection directory. It is responsible for training a YOLO detection model for object detection in images.                                                                                                                                                                                                    |
| [device](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/device)                   | The code snippet in the `map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/device` file is responsible for configuring the device (CPU or GPU) to be used for the YOLO object detection model in the Map-Action-Model repository.                                                                                                                                         |
| [cls](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/cls)                         | This code snippet is part of the Map Action Model repository and is located in the `map_action_yolo_detection` directory. It contains code related to running the YOLO object detection model. The specific file mentioned (`runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/cls`) appears to store a parameter value for the confidence threshold used in the object detection model.            |
| [project](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/project)                 | This code snippet is part of the Map-Action-Model repository and is located in the code/map_action_yolo_detection directory. It is responsible for running the YOLO object detection model.                                                                                                                                                                                                                              |
| [pose](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/pose)                       | The code snippet in the `code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/pose` file is responsible for storing and retrieving the value 12.0 related to the pose parameter in the MLflow run.                                                                                                                                                                      |
| [save_dir](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/save_dir)               | The code snippet in the code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/save_dir file saves the trained YOLO model and its associated files in the runs/detect/train directory. It plays a critical role in the model's workflow, enabling trained models to be stored and later accessed for detection tasks.                                                     |
| [workers](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/workers)                 | The code snippet in the code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/workers file sets the number of workers to 0 in the YOLO object detection model for the Map Action project.                                                                                                                                                                                |
| [save_hybrid](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/save_hybrid)         | The code snippet in the map_action_yolo_detection folder of the repository is related to YOLO detection. It includes files for training and running object detection models based on YOLO architecture.                                                                                                                                                                                                                  |
| [mask_ratio](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/mask_ratio)           | The code in the `map_action_yolo_detection` directory performs object detection using the YOLO algorithm. It includes training and inference capabilities, with the ability to adjust mask ratios.                                                                                                                                                                                                                       |
| [dfl](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/dfl)                         | The code snippet in the `map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/dfl` file is a configuration file that specifies the value `1.5`. It likely represents a parameter used in the YOLO object detection model, but without further context, its exact purpose is unclear.                                                                                         |
| [int8](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/int8)                       | The code snippet in the `map_action_yolo_detection/runs` folder is used for training a YOLO object detection model. It contains files and configurations for training the model using MLflow, with a specific parameter value for int8 set to False.                                                                                                                                                                     |
| [exist_ok](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/exist_ok)               | This code snippet is located in the map_action_yolo_detection directory of the repository. It appears to be related to YOLO object detection model training and includes files such as yolo_train.ipynb and yolo_train.py. The specific purpose and functionality of the code snippet within the parent repository's architecture cannot be determined without further analysis.                                         |
| [deterministic](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/deterministic)     | The code in the `map_action_yolo_detection` directory is focused on implementing object detection using the YOLO algorithm. It includes files for data loading, training, and model evaluation. It also uses MLflow for experiment tracking.                                                                                                                                                                             |
| [nbs](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/nbs)                         | The code snippet is part of the Map-Action-Model repository and is located in the `code/map_action_yolo_detection` directory. It is related to running YOLO object detection models and has a dependency on the MLflow library. The specific file mentioned contains 64 parameters.                                                                                                                                      |
| [mixup](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/mixup)                     | The code snippet is part of the Map Action Model repository and specifically relates to the map_action_yolo_detection module. It includes training and testing functions for YOLO object detection models. The provided file path and contents are not directly related to the code's main role or critical features.                                                                                                    |
| [stream_buffer](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/stream_buffer)     | This code snippet is part of the Map-Action-Model repository. It handles YOLO object detection and includes a parameter file to control the stream buffer.                                                                                                                                                                                                                                                               |
| [conf](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/conf)                       | This code snippet in the `map_action_yolo_detection` directory is responsible for training a YOLO object detection model. It uses the configuration parameters specified in the referenced file to define the model's behavior during the training process.                                                                                                                                                              |
| [warmup_momentum](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/warmup_momentum) | This code snippet is part of the Map-Action-Model repository. It contributes to the YOLO detection model by setting the warmup momentum parameter to 0.8 for the training process.                                                                                                                                                                                                                                       |
| [name](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/name)                       | The code snippet in the map_action_yolo_detection module is responsible for training a YOLO object detection model. It uses the MLflow library to track the training process and retrieve the hyperparameters used for training. The specific run referenced in the given file path has the name train.                                                                                                                  |
| [label_smoothing](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/label_smoothing) | The `label_smoothing` parameter in `code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/label_smoothing` file is set to `0.0`. This code snippet pertains to the Map Action YOLO Detection model and controls the smoothing of the labels used during training.                                                                                                        |
| [lr0](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/lr0)                         | The code snippet in the code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/lr0 file pertains to the parent repository's YOLO (You Only Look Once) object detection model. It includes the parameter for the learning rate, which is set to 0.01. This code snippet plays a critical role in configuring the learning rate for the YOLO model's training process.      |
| [save_txt](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/save_txt)               | The code snippet in the `map_action_yolo_detection` directory is responsible for training a YOLO-based object detection model. It includes files for data loading, training, and the trained model's parameters.                                                                                                                                                                                                         |
| [format](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/format)                   | This code snippet is part of the Map-Action-Model repository and is focused on the YOLO object detection model. It utilizes TorchScript format for the model parameters.                                                                                                                                                                                                                                                 |
| [dynamic](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/dynamic)                 | The code snippet in `code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/dynamic` is not dynamic according to the file contents.                                                                                                                                                                                                                                       |
| [task](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/task)                       | This code snippet in the map_action_yolo_detection module is responsible for performing object detection using the YOLO algorithm, as indicated by the detect parameter in the specified file.                                                                                                                                                                                                                           |
| [agnostic_nms](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/agnostic_nms)       | The code snippet in the map_action_yolo_detection folder trains a YOLO (You Only Look Once) object detection model using MLflow. It sets the agnostic_nms parameter to False for non-maximum suppression.                                                                                                                                                                                                                |
| [save_period](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/save_period)         | The code snippet in the map_action_yolo_detection folder performs object detection using the YOLO algorithm. It is responsible for training the model and saving it at a specified interval. The specific path code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/save_period contains a parameter that determines the frequency of saving the model during training. |
| [dropout](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/dropout)                 | This code snippet is part of the Map Action Model repository. It focuses on the YOLO detection model, with the specific file dropout having a value of 0.0 for the dropout parameter.                                                                                                                                                                                                                                    |
| [show](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/show)                       | The code snippet in `code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/show` determines whether to show the results of the YOLO object detection model.                                                                                                                                                                                                              |
| [resume](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/resume)                   | This code snippet is part of the Map-Action-Model repository and is located in the code/map_action_yolo_detection directory. It includes files for training a YOLO-based object detection model. The specific purpose of this snippet is to check if the training should resume from a previous checkpoint or start a new training session.                                                                              |
| [hsv_v](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/hsv_v)                     | This code snippet is part of the Map-Action-Model repository. It includes a YOLO object detection model for image analysis. The specific file mentioned contains a parameter for setting the saturation value in the HSV color space.                                                                                                                                                                                    |
| [classes](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/classes)                 | The code snippet in the map_action_yolo_detection directory is responsible for training a YOLO object detection model. It uses the classes specified in the classes file as the target classes for the model to detect.                                                                                                                                                                                                  |
| [warmup_bias_lr](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/warmup_bias_lr)   | The code snippet `warmup_bias_lr` located at `code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/` contains the value `0.0`. This parameter is used for bias learning rate warmup during training in the YOLO-based object detection model.                                                                                                                           |
| [save_crop](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/save_crop)             | The code snippet in `map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/save_crop` determines whether to save the cropped images during object detection.                                                                                                                                                                                                                  |
| [imgsz](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/imgsz)                     | The code snippet in the `code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/imgsz` file specifies the image size parameter for the YOLO object detection model in the Map Action repository.                                                                                                                                                                          |
| [half](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/half)                       | The code snippet in the code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/half file is responsible for configuring the half parameter for the YOLO object detection model in the Map Action repository.                                                                                                                                                              |
| [batch](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/batch)                     | The code snippet in the file `code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/batch` contains 16 lines of code. However, without the actual code, it is difficult to determine its exact role and critical features within the parent repository's architecture.                                                                                                   |
| [verbose](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/verbose)                 | The code in the `map_action_yolo_detection` directory is responsible for training and running object detection models using the YOLO algorithm. It includes scripts for data loading, training, and model evaluation. The specific code snippet mentioned in the question sets the verbosity parameter to `True`, enabling more detailed output during model execution.                                                  |
| [mosaic](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/mosaic)                   | The code snippet in `code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/mosaic` contains the parameter value `1.0` for the mosaic technique used in the YOLO object detection model in the Map-Action-Model repository.                                                                                                                                               |
| [optimizer](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/optimizer)             | The code snippet in `code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/optimizer` is a configuration file that defines the optimizer used in training the YOLO object detection model in the Map-Action-Model repository.                                                                                                                                            |
| [dnn](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/dnn)                         | This code snippet is part of the Map-Action-Model repository and is responsible for training a YOLO object detection model. It achieves this by configuring the model parameters and data loading pipeline. Further technical implementation details are not provided.                                                                                                                                                   |
| [rect](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/rect)                       | The code snippet in the `code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/rect` file controls the flag for whether to use rectangular bounding boxes in the object detection model. The code achieves the feature of toggling rectangular bounding boxes on or off in the model.                                                                                    |
| [flipud](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/flipud)                   | The code snippet in the `code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/flipud` file is related to the Map Action YOLO Detection model. It contains a parameter `flipud` with a value of `0.0`. This parameter likely controls the flipping of images vertically during the detection process.                                                                    |
| [weight_decay](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/weight_decay)       | This code snippet in the `map_action_yolo_detection` directory of the repository is responsible for running the YOLO object detection model using the weight decay parameter. The file `weight_decay` contains the value of 0.0005.                                                                                                                                                                                      |
| [workspace](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/workspace)             | The code snippet in the `runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/workspace` file is a configuration file that contains four parameters related to the workspace. It is a critical feature for setting up and defining the workspace environment in the Map Action Model repository.                                                                                                       |
| [shear](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/shear)                     | This code snippet is part of the Map-Action-Model repository and is located in the map_action_yolo_detection directory. It contains the configuration parameter for shear transformation in image processing.                                                                                                                                                                                                            |
| [line_width](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/line_width)           | This code snippet is part of the `Map-Action-Model` repository and is located in the `map_action_yolo_detection` directory. It is related to the `yolo_train.py` file and is responsible for setting the line width parameter for YOLO object detection.                                                                                                                                                                 |
| [cache](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/cache)                     | The code snippet in the `map_action_yolo_detection` directory is responsible for training and running object detection models using the YOLO algorithm. It includes data loading, model training, and model evaluation. It also utilizes MLflow for experiment tracking and caching.                                                                                                                                     |
| [freeze](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/freeze)                   | The code snippet in the map_action_yolo_detection folder is responsible for running the YOLO object detection model. It uses mlflow and contains parameters for freezing the model.                                                                                                                                                                                                                                      |
| [vid_stride](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/vid_stride)           | This code snippet in the map_action_yolo_detection directory of the repository is responsible for specifying the video stride parameter for the YOLO object detection model. It sets the stride value to 1.                                                                                                                                                                                                              |
| [iou](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/iou)                         | This code snippet, located in the Map-Action-Model repository under the code/map_action_yolo_detection directory, contains the parameters for intersection over union (IoU) calculation in the YOLO object detection model. The value is set to 0.7.                                                                                                                                                                     |
| [mode](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/mode)                       | The code snippet in the map_action_yolo_detection directory performs training for object detection using the YOLO algorithm. The code is responsible for training the model and optimizing the detection accuracy. It reads the mode parameter from a file in the MLflow run, indicating that the code is executed in training mode.                                                                                     |
| [save](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/params/save)                       | The code snippet in the `map_action_yolo_detection` directory is responsible for running and saving a YOLO detection model. It includes files for data loading, training, and the trained model.                                                                                                                                                                                                                         |

</details>

<details closed><summary>code.map_action_yolo_detection.runs.mlflow.452260836794962566.3bf8731e14554e2c99db9c7292999de0.metrics.val</summary>

| File                                                                                                                                                                                         | Summary                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |
| ---                                                                                                                                                                                          | ---                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |
| [dfl_loss](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/metrics/val/dfl_loss) | This code snippet is part of the Map-Action-Model repository's architecture. It contributes to the map action YOLO detection model and is responsible for calculating the loss during validation.                                                                                                                                                                                                                                                                                                        |
| [cls_loss](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/metrics/val/cls_loss) | This code snippet is part of the Map-Action-Model repository and is located in the `code/map_action_yolo_detection` directory. It is related to YOLO object detection and includes files for data loading, model training, and evaluation. The specific file mentioned (`code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/metrics/val/cls_loss`) contains the value 5.41091, which likely corresponds to the classification loss metric during validation. |
| [box_loss](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/metrics/val/box_loss) | The code snippet in the `map_action_yolo_detection` directory is responsible for training a YOLO object detection model. The code achieves this by implementing the YOLO training algorithm and optimizing the loss function for bounding box predictions. The mentioned file path contains the validation loss metric for the trained model.                                                                                                                                                            |

</details>

<details closed><summary>code.map_action_yolo_detection.runs.mlflow.452260836794962566.3bf8731e14554e2c99db9c7292999de0.metrics.metrics</summary>

| File                                                                                                                                                                                                 | Summary                                                                                                                                                                                                                                                                                                                                               |
| ---                                                                                                                                                                                                  | ---                                                                                                                                                                                                                                                                                                                                                   |
| [mAP50-95B](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/metrics/metrics/mAP50-95B)   | The code snippet in `map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/metrics/metrics/mAP50-95B` file calculates the mean average precision (mAP) for object detection using the YOLO algorithm. It measures the accuracy of the model in detecting objects with a confidence threshold between 50% and 95%. |
| [recallB](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/metrics/metrics/recallB)       | The code snippet is part of the Map-Action-Model repository and specifically belongs to the map_action_yolo_detection module. It includes files for data loading, model training, and inference for object detection tasks using the YOLO algorithm.                                                                                                  |
| [mAP50B](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/metrics/metrics/mAP50B)         | The code snippet in the `code/map_action_yolo_detection` directory is responsible for running the YOLO object detection model, which includes training and evaluating the model's performance. It outputs the mean Average Precision (mAP) at 50% IoU threshold.                                                                                      |
| [precisionB](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/metrics/metrics/precisionB) | This code snippet is part of the Map-Action-Model repository. It is responsible for running the MLflow tracking system to monitor the precision of the YOLO object detection model used in the Map Action project. The precision value is stored in the specified file path.                                                                          |

</details>

<details closed><summary>code.map_action_yolo_detection.runs.mlflow.452260836794962566.3bf8731e14554e2c99db9c7292999de0.tags</summary>

| File                                                                                                                                                                                                                  | Summary                                                                                                                                                                                                                                                                                                                                       |
| ---                                                                                                                                                                                                                   | ---                                                                                                                                                                                                                                                                                                                                           |
| [mlflow.source.git.commit](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/tags/mlflow.source.git.commit) | The code in the `map_action_yolo_detection` directory is responsible for training a model using the YOLO (You Only Look Once) algorithm for object detection. It includes scripts for data loading, training, and evaluation. The specific commit for this code is 785a1c7b75343744bfe8516664b1c0ea2ae5414d.                                  |
| [mlflow.source.type](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/tags/mlflow.source.type)             | The code snippet in the `code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/tags/mlflow.source.type` file is responsible for determining the source type of the MLflow experiment run.                                                                                                            |
| [mlflow.runName](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/tags/mlflow.runName)                     | The code snippet in the map_action_yolo_detection directory is responsible for training a YOLO object detection model. It uses MLflow for experiment tracking and the training script is identified with the tag mlflow.runName=train.                                                                                                        |
| [mlflow.source.name](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/tags/mlflow.source.name)             | The code snippet in the file yolo_train.py is a critical feature of the Map-Action-Model repository's architecture. It is responsible for training a YOLO object detection model. For more details, refer to the code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/tags/mlflow.source.name file. |
| [mlflow.user](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/tags/mlflow.user)                           | The code snippet in `code/map_action_yolo_detection/runs/mlflow/452260836794962566/3bf8731e14554e2c99db9c7292999de0/tags/mlflow.user` sets the user tag to yugo19 in the MLflow experiment run.                                                                                                                                               |

</details>

<details closed><summary>code.map_action_yolo_detection.runs.mlflow.0</summary>

| File                                                                                                                             | Summary                                                                                                                                                     |
| ---                                                                                                                              | ---                                                                                                                                                         |
| [meta.yaml](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_yolo_detection/runs/mlflow/0/meta.yaml) | This code snippet implements the Map Action YOLO Detection model in the Map Action Model repository. It performs object detection using the YOLO algorithm. |

</details>

<details closed><summary>code.map_action_classification_model</summary>

| File                                                                                                                                                   | Summary                                                                                                                                                                                                                                                                                                                                                                                         |
| ---                                                                                                                                                    | ---                                                                                                                                                                                                                                                                                                                                                                                             |
| [utilities.ipynb](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_classification_model/utilities.ipynb)                   | This code snippet, located in the `code/map_action_classification_model/utilities.ipynb` file, attempts to import various dependencies and retrieve data from a specific data source. However, it throws a `SyntaxError` on line 22 due to an invalid syntax in the code. This issue needs to be resolved for the code to execute successfully.                                                 |
| [train.py](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_classification_model/train.py)                                 | The `train.py` file in the `code/map_action_classification_model` directory is responsible for training a classification model. It imports necessary modules, creates data loaders, defines the model, loss function, and optimizer, and initiates a training pipeline. The code performs the training process and returns the results.                                                         |
| [dagshub_data_load.py](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_classification_model/dagshub_data_load.py)         | The code snippet in dagshub_data_load.py handles the loading and filtering of data from a specified datasource. It organizes the data into train, valid, and test directories, splitting the images based on specified conditions. The code is part of the map_action_classification_model component in the parent repository's architecture.                                                   |
| [training_utils.py](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_classification_model/training_utils.py)               | This code snippet implements the TrainingPipeline class within the map_action_classification_model module. It provides methods for training and testing a neural network model using a specified optimizer and loss function. The class keeps track of training and testing results.                                                                                                            |
| [m_a_model.py](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_classification_model/m_a_model.py)                         | The code snippet in m_a_model.py defines a function that creates a modified VGG16 model for map action classification. It loads the VGG16 model with batch normalization weights, freezes all parameters, and modifies the classifier to adapt to the specified number of classes. The resulting model is returned.                                                                             |
| [m_a_utility.py](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_classification_model/m_a_utility.py)                     | This code snippet in `m_a_utility.py` is part of the `map_action_classification_model` module. It provides utility functions for the Map Action classification model.                                                                                                                                                                                                                           |
| [data_loading_pipeline.py](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_classification_model/data_loading_pipeline.py) | The code snippet in `data_loading_pipeline.py` provides a function `create_dataloaders` that generates data loaders for training, validation, and testing data. It utilizes the `torchvision.datasets.ImageFolder` to load the data and converts them into data loaders with specified batch size and number of workers. The function also returns the class names associated with the dataset. |
| [TFLearning.ipynb](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_classification_model/TFLearning.ipynb)                 | This code snippet serves as a critical component in the parent repository's architecture. Its main role is to achieve a specific functionality while abstracting the implementation details. Further details about the codebase can be found in the provided materials.                                                                                                                         |
| [data_transform.py](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_classification_model/data_transform.py)               | This code snippet defines a function called `get_transform` that returns a composition of image transformations. These transformations include random horizontal flipping, random resized cropping, normalization, converting to float, and converting to a PyTorch tensor. The function takes a boolean parameter `train` to specify whether the transformations are for training or not.      |

</details>

<details closed><summary>code.map_action_classification_model..zen</summary>

| File                                                                                                                              | Summary                                                                                                                                                                                                                                                                                                                                                                            |
| ---                                                                                                                               | ---                                                                                                                                                                                                                                                                                                                                                                                |
| [config.yaml](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_classification_model/.zen/config.yaml) | The code snippet in `map_action_classification_model` is part of a larger repository called `Map-Action-Model`. It plays a critical role in the classification of map actions. The code achieves this by implementing various data loading, transformation, and training pipelines. The primary objective is to create a model that can classify different map actions accurately. |

</details>

<details closed><summary>code.map_action_classification_model.pipelines</summary>

| File                                                                                                                                               | Summary                                                                                                                                                                                                                                                                                                                                               |
| ---                                                                                                                                                | ---                                                                                                                                                                                                                                                                                                                                                   |
| [zenml_pipeline.py](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_classification_model/pipelines/zenml_pipeline.py) | This code snippet is part of the Map Action Model repository's architecture. It defines a ZenML training pipeline for a map action classification model. The pipeline includes steps for data retrieval, data preparation, model training, and evaluation. It makes use of MLflow for tracking and logging the training process.                      |
| [zenml_running.py](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_classification_model/pipelines/zenml_running.py)   | The code snippet in `code/map_action_classification_model/pipelines/zenml_running.py` is responsible for creating a ZenML training pipeline for a map action classification model. It imports necessary libraries, defines the model configuration, sets up data loading, transforms, training, and evaluation steps, and runs the training pipeline. |

</details>

<details closed><summary>code.map_action_classification_model.step</summary>

| File                                                                                                                                                        | Summary                                                                                                                                                                                                                                                                                                                                                                       |
| ---                                                                                                                                                         | ---                                                                                                                                                                                                                                                                                                                                                                           |
| [dagshub_data_load.py](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_classification_model/step/dagshub_data_load.py)         | The code snippet in the file dagshub_data_load.py is responsible for downloading and organizing data for the map action classification model. It accesses a CSV file, downloads images from a given URL, and organizes them into train, valid, and test directories. The resulting directories are returned as outputs.                                                       |
| [m_a_model.py](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_classification_model/step/m_a_model.py)                         | This code snippet, located at `code/map_action_classification_model/step/m_a_model.py`, defines a step function that creates a modified VGG16 model for map action classification. It loads the VGG16 model with batch normalization weights, freezes all parameters, and modifies the classifier to adapt to the number of classes. The function returns the modified model. |
| [data_loading_pipeline.py](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_classification_model/step/data_loading_pipeline.py) | This code snippet defines a step called create_dataloaders in the Map-Action-Model repository. It creates data loaders for training, testing, and validation using the torchvision library. It also returns the class names for the dataset.                                                                                                                                  |
| [evaluation.py](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_classification_model/step/evaluation.py)                       | Summary: The `test_step` function in the `code/map_action_classification_model/step/evaluation.py` file is responsible for evaluating the performance of a model on a test dataset. It calculates the test loss and accuracy, logs them using MLflow, and saves the PyTorch model as an artifact.                                                                             |
| [training_step.py](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_classification_model/step/training_step.py)                 | This code snippet defines a step for training a PyTorch model. It takes in a neural network model, a training dataloader, an optimizer, and a loss function. It performs multiple epochs of training, calculates the loss and accuracy, and logs the model using MLflow. The trained model and training results are returned.                                                 |
| [data_transform.py](https://github.com/223MapAction/Map-Action-Model/blob/master/code/map_action_classification_model/step/data_transform.py)               | The code snippet in `data_transform.py` defines a function `get_transform` that generates a composition of image transformations using the torchvision library. These transformations include random horizontal flipping, resizing and cropping, normalization, converting to float, and converting to a PyTorch tensor.                                                      |

</details>

<details closed><summary>code.vision_dir</summary>

| File                                                                                                                              | Summary                                                                                                                                                                                                                                                                                                                                                                                                                                  |
| ---                                                                                                                               | ---                                                                                                                                                                                                                                                                                                                                                                                                                                      |
| [train.py](https://github.com/223MapAction/Map-Action-Model/blob/master/code/vision_dir/train.py)                                 | The code snippet in the map_action_classification_model directory is responsible for implementing the map action classification model. It includes various components such as data loading, data transformation, model training, and utility functions.                                                                                                                                                                                  |
| [utils.py](https://github.com/223MapAction/Map-Action-Model/blob/master/code/vision_dir/utils.py)                                 | This code snippet provides utility functions for distributed training and logging in the context of the parent repository's architecture. It includes functionality for tracking and averaging values, synchronizing data between processes, gathering data from each rank, reducing dictionary values, and setting up distributed training.                                                                                             |
| [transforms.py](https://github.com/223MapAction/Map-Action-Model/blob/master/code/vision_dir/transforms.py)                       | This code snippet is part of the Map Action Model repository. It includes a collection of modules and scripts related to map action classification and image captioning. The code achieves the training and utilization of machine learning models for these tasks.                                                                                                                                                                      |
| [coco_utils.py](https://github.com/223MapAction/Map-Action-Model/blob/master/code/vision_dir/coco_utils.py)                       | The code snippet in `coco_utils.py` provides utility functions for converting COCO dataset annotations to masks and vice versa. It also includes functions for removing images without annotations and converting datasets to the COCO API format. These functions are essential for handling and manipulating COCO dataset annotations within the parent repository's architecture.                                                     |
| [coco_eval.py](https://github.com/223MapAction/Map-Action-Model/blob/master/code/vision_dir/coco_eval.py)                         | The code snippet, located in the file coco_eval.py, provides a class called CocoEvaluator that is responsible for evaluating object detection models using the COCO evaluation metrics. It prepares predictions in different formats (bbox, segm, keypoints) and calculates evaluation results. Additionally, it includes methods for synchronization, accumulation, and summarization of evaluation metrics.                            |
| [engine.py](https://github.com/223MapAction/Map-Action-Model/blob/master/code/vision_dir/engine.py)                               | The `engine.py` file in the `vision_dir` directory of the codebase is responsible for training and evaluating a model for object detection. It includes functions for training one epoch, evaluating, and getting the intersection over union (IOU) types used by the model. The code handles data loading, model optimization, and logging metrics. It also uses the COCO dataset for evaluation and calculates performance statistics. |
| [presets.py](https://github.com/223MapAction/Map-Action-Model/blob/master/code/vision_dir/presets.py)                             | The code snippet in `presets.py` is responsible for defining preset transformations for training and evaluation in a computer vision model. It includes various data augmentation techniques and backend options. The `DetectionPresetTrain` class is used for training, while the `DetectionPresetEval` class is used for evaluation. These presets ensure consistent and efficient data processing in the model.                       |
| [group_by_aspect_ratio.py](https://github.com/223MapAction/Map-Action-Model/blob/master/code/vision_dir/group_by_aspect_ratio.py) | The code snippet `group_by_aspect_ratio.py` provides a `GroupedBatchSampler` class that batches indices from a sampler based on group IDs. It ensures that each batch contains elements from the same group and maintains an ordering similar to the original sampler. The code also includes functions to compute aspect ratios for various dataset types and create aspect ratio groups.                                               |

</details>

---

## üöÄ Getting Started

***Requirements***

Ensure you have the following dependencies installed on your system:

* **Python**: `version x.y.z`

### ‚öôÔ∏è Installation

1. Clone the Map-Action-Model repository:

```sh
git clone https://github.com/223MapAction/Map-Action-Model
```

2. Change to the project directory:

```sh
cd Map-Action-Model
```

3. Install the dependencies:

```sh
pip install -r requirements.txt
```

### ü§ñ Running Map-Action-Model

Use the following command to run Map-Action-Model:

```sh
python main.py
```

### üß™ Tests

To execute tests, run:

```sh
pytest
```

---

## üõ† Project Roadmap

- [X] `‚ñ∫ INSERT-TASK-1`
- [ ] `‚ñ∫ INSERT-TASK-2`
- [ ] `‚ñ∫ ...`

---

## ü§ù Contributing

Contributions are welcome! Here are several ways you can contribute:

See our [Contribution Guidelines](CONTRIBUTING.md) for details on how to contribute.


---

## üìÑ License

This project is protected under the [GNU GPLv3](https://choosealicense.com/licenses/gpl-3.0/) License. For more details, refer to the [LICENSE](https://choosealicense.com/licenses/) file.

---

## Code of conduct

See our [Code of Conduct](CODE_OF_CONDUCT.md) for details on expected behavior in our community.

---

## üëè Acknowledgments

- List any resources, contributors, inspiration, etc. here.

[**Return**](#-quick-links)

---
